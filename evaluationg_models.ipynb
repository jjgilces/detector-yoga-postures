{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedTransferNetVGG19(models.Model):\n",
    "    def __init__(self, base_model_weights=None):\n",
    "        super(ImprovedTransferNetVGG19, self).__init__()\n",
    "        self.base_model = tf.keras.applications.VGG19(include_top=False, weights=base_model_weights, input_shape=(224, 224, 3))\n",
    "        for layer in self.base_model.layers:\n",
    "            layer.trainable = False  # Freeze VGG19 layers initially\n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        l1lambda = 0.0001\n",
    "        # Dense layers with reduced neurons\n",
    "        self.fc1 = layers.Dense(1024, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(l1lambda))\n",
    "        self.fc1_bn = layers.BatchNormalization()\n",
    "        self.fc1_dropout = layers.Dropout(0.4)\n",
    "\n",
    "        self.fc2 = layers.Dense(512, activation='relu')\n",
    "        self.fc2_bn = layers.BatchNormalization()\n",
    "        self.fc2_dropout = layers.Dropout(0.4)\n",
    "        \n",
    "        self.fc3 = layers.Dense(128, activation='relu')\n",
    "        self.fc3_bn = layers.BatchNormalization()\n",
    "        self.fc3_dropout = layers.Dropout(0.4)\n",
    "\n",
    "        self.fc4 = layers.Dense(4, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_bn(x)\n",
    "        x = self.fc1_dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_bn(x)\n",
    "        x = self.fc2_dropout(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc3_bn(x)\n",
    "        x = self.fc3_dropout(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    def unfreeze_last_layers(self, num_layers=6):\n",
    "        \"\"\"Desbloquea las últimas num_layers del modelo base.\"\"\"\n",
    "        for layer in self.base_model.layers[-num_layers:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"base_model_name\": \"VGG19\"}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        if config[\"base_model_name\"] == \"VGG19\":\n",
    "            return cls(base_model_weights=\"imagenet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset_dir, train_dir, val_dir, test_dir, split_ratio=(0.8, 0.1, 0.1)):\n",
    "    # If the directory already exists, delete it\n",
    "    for directory in [train_dir, val_dir, test_dir]:\n",
    "        if os.path.exists(directory):\n",
    "            shutil.rmtree(directory)\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Collect the filenames\n",
    "    image_files = os.listdir(dataset_dir)\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Split the data\n",
    "    total_images = len(image_files)\n",
    "    num_train = int(total_images * split_ratio[0])\n",
    "    num_val = int(total_images * split_ratio[1])\n",
    "    num_test = total_images - num_train - num_val\n",
    "\n",
    "    # Copy the images to the correct directory\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        src_path = os.path.join(dataset_dir, image_file)\n",
    "        if i < num_train:\n",
    "            dst_path = os.path.join(train_dir, image_file)\n",
    "        elif i < num_train + num_val:\n",
    "            dst_path = os.path.join(val_dir, image_file)\n",
    "        else:\n",
    "            dst_path = os.path.join(test_dir, image_file)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "    print(\"Splitting data completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data completed.\n",
      "Splitting data completed.\n",
      "Splitting data completed.\n",
      "Splitting data completed.\n"
     ]
    }
   ],
   "source": [
    "# Define paths for the images\n",
    "downdog_SRC_DIR = \"FINALDATA/downdog\"\n",
    "plank_SRC_DIR = \"FINALDATA/plank\"\n",
    "tree_SRC_DIR = \"FINALDATA/tree\"\n",
    "warrior_SRC_DIR = \"FINALDATA/warrior\"\n",
    "TRAINING_DIR = \"dataset/training\"\n",
    "VALIDATION_DIR = \"dataset/validation\"\n",
    "TEST_DIR = \"dataset/test\"\n",
    "#splitting the dataset\n",
    "TRAINING_DDG_DIR = os.path.join(TRAINING_DIR, \"downdog/\")\n",
    "VALIDATION_DDG_DIR = os.path.join(VALIDATION_DIR, \"downdog/\")\n",
    "TEST_DDG_DIR = os.path.join(TEST_DIR, \"downdog/\")\n",
    "\n",
    "TRAINING_PLANK_DIR = os.path.join(TRAINING_DIR, \"plank/\")\n",
    "VALIDATION_PLANK_DIR = os.path.join(VALIDATION_DIR, \"plank/\")\n",
    "TEST_PLANK_DIR = os.path.join(TEST_DIR, \"plank/\")\n",
    "\n",
    "TRAINING_TREE_DIR = os.path.join(TRAINING_DIR, \"tree/\")\n",
    "VALIDATION_TREE_DIR = os.path.join(VALIDATION_DIR, \"tree/\")\n",
    "TEST_TREE_DIR = os.path.join(TEST_DIR, \"tree/\")\n",
    "\n",
    "TRAINING_WR_DIR = os.path.join(TRAINING_DIR, \"warrior/\")\n",
    "VALIDATION_WR_DIR = os.path.join(VALIDATION_DIR, \"warrior/\")\n",
    "TEST_WR_DIR = os.path.join(TEST_DIR, \"warrior/\")\n",
    "# Define proportion of images used for training\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "split_data(downdog_SRC_DIR,\n",
    "           TRAINING_DDG_DIR,\n",
    "           VALIDATION_DDG_DIR,\n",
    "           TEST_DDG_DIR,\n",
    "           split_ratio=(train_size,val_size, test_size))\n",
    "\n",
    "split_data(plank_SRC_DIR,\n",
    "           TRAINING_PLANK_DIR,\n",
    "           VALIDATION_PLANK_DIR,\n",
    "           TEST_PLANK_DIR,\n",
    "           split_ratio=(train_size,val_size, test_size))\n",
    "\n",
    "split_data(tree_SRC_DIR,\n",
    "           TRAINING_TREE_DIR,\n",
    "           VALIDATION_TREE_DIR,\n",
    "           TEST_TREE_DIR,\n",
    "           split_ratio=(train_size,val_size, test_size))\n",
    "split_data(warrior_SRC_DIR,\n",
    "           TRAINING_WR_DIR,\n",
    "           VALIDATION_WR_DIR,\n",
    "           TEST_WR_DIR,\n",
    "           split_ratio=(train_size,val_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1769 images belonging to 4 classes.\n",
      "Found 55 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Definir un generador de imágenes con transformaciones\n",
    "batch_size = 32\n",
    "width=224\n",
    "height=224\n",
    "posture_names = [\"downdog\", \"plank\", \"tree\", \"warrior\"]\n",
    "data_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=[0.6,1.0],\n",
    "    validation_split=0.20\n",
    ")\n",
    "\n",
    "train_data = data_generator.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    classes = posture_names,\n",
    "    target_size=(width, height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  \n",
    "    subset='training',\n",
    "    color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "validation_data = data_generator.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    classes = posture_names,\n",
    "    target_size=(width, height),\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_instance():\n",
    "    return ImprovedTransferNetVGG19(base_model_weights=None)  # Aquí no cargamos los pesos preentrenados de VGG19 ya que vamos a cargar tus pesos guardados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' block1_conv1/kernel:0': Shape mismatch.The variable shape (3, 3, 3, 64), and the assigned value shape (512, 512, 3, 3) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_instance \u001b[39m=\u001b[39m create_model_instance()\n\u001b[1;32m      2\u001b[0m model_instance\u001b[39m.\u001b[39mbuild((\u001b[39mNone\u001b[39;00m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m3\u001b[39m))  \u001b[39m# Esto es necesario para construir el modelo antes de cargar los pesos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model_instance\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39mv5.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/keras/src/backend.py:4361\u001b[0m, in \u001b[0;36m_assign_value_to_variable\u001b[0;34m(variable, value)\u001b[0m\n\u001b[1;32m   4358\u001b[0m     variable\u001b[39m.\u001b[39massign(d_value)\n\u001b[1;32m   4359\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4360\u001b[0m     \u001b[39m# For the normal tf.Variable assign\u001b[39;00m\n\u001b[0;32m-> 4361\u001b[0m     variable\u001b[39m.\u001b[39;49massign(value)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' block1_conv1/kernel:0': Shape mismatch.The variable shape (3, 3, 3, 64), and the assigned value shape (512, 512, 3, 3) are incompatible."
     ]
    }
   ],
   "source": [
    "model_instance = create_model_instance()\n",
    "model_instance.build((None, 224, 224, 3))  # Esto es necesario para construir el modelo antes de cargar los pesos\n",
    "model_instance.load_weights('v5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'validation_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam()  \u001b[39m# Puedes usar el optimizador que prefieras\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model_instance\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, \n\u001b[1;32m     11\u001b[0m                        loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(), \n\u001b[1;32m     12\u001b[0m                        metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model_instance\u001b[39m.\u001b[39mevaluate(validation_data, validation_labels)\n\u001b[1;32m     15\u001b[0m evaluation_results[model_file] \u001b[39m=\u001b[39m (loss, accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validation_labels' is not defined"
     ]
    }
   ],
   "source": [
    "model_files = ['v2.h5',  'v4.h5']\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_file in model_files:\n",
    "    model_instance = create_model_instance()\n",
    "    model_instance.build((None, 224, 224, 3))  # Esto es necesario para construir el modelo antes de cargar los pesos\n",
    "    model_instance.load_weights(model_file)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam()  # Puedes usar el optimizador que prefieras\n",
    "    model_instance.compile(optimizer=optimizer, \n",
    "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    loss, accuracy = model_instance.evaluate(validation_data, validation_labels)\n",
    "    evaluation_results[model_file] = (loss, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(evaluation_results, key=lambda x: evaluation_results[x][1])  # Obtenemos el modelo con la máxima precisión\n",
    "print(f\"El mejor modelo es: {best_model_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(evaluation_results, key=evaluation_results.get)\n",
    "print(f\"El mejor modelo es: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'determine_if_finetuned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m model_file \u001b[39min\u001b[39;00m model_files:\n\u001b[0;32m---> 30\u001b[0m     is_finetuned \u001b[39m=\u001b[39m determine_if_finetuned(model_file)  \u001b[39m# Función que necesitas crear para saber si el modelo fue fine-tuned\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     loss, accuracy \u001b[39m=\u001b[39m evaluate_model(model_file, is_finetuned)\n\u001b[1;32m     32\u001b[0m     results[model_file] \u001b[39m=\u001b[39m (loss, accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'determine_if_finetuned' is not defined"
     ]
    }
   ],
   "source": [
    "# Lista de tus archivos .h5\n",
    "model_files = [\"v1.h5\", \"v2.h5\", \"v3.h5\", \"v4.h5\"]\n",
    "\n",
    "# Función para evaluar un modelo\n",
    "def evaluate_model(model_file, is_finetuned=False):\n",
    "    # Crear una instancia de tu modelo\n",
    "    model = ImprovedTransferNetVGG19(base_model_weights=None)\n",
    "    \n",
    "    # Si el modelo fue fine-tuned, descongela las capas adecuadas\n",
    "    if is_finetuned:\n",
    "        model.unfreeze_last_layers(num_layers=6)\n",
    "    \n",
    "    # Compilar el modelo (puedes ajustar estos parámetros según lo necesites)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Cargar los pesos\n",
    "    model.load_weights(model_file)\n",
    "    \n",
    "    # Evaluar el modelo con tu conjunto de validación/test\n",
    "    loss, accuracy = model.evaluate(validation_data)\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "# Evalúa cada modelo y almacena sus resultados\n",
    "results = {}\n",
    "for model_file in model_files:\n",
    "    is_finetuned = determine_if_finetuned(model_file)  # Función que necesitas crear para saber si el modelo fue fine-tuned\n",
    "    loss, accuracy = evaluate_model(model_file, is_finetuned)\n",
    "    results[model_file] = (loss, accuracy)\n",
    "\n",
    "# Imprime los resultados o decide qué modelo es el mejor según tus criterios\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.h5 (fine-tuned) cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:38:18.934522: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 1s/step - loss: 4.9335 - accuracy: 0.5636\n",
      "v2.h5 cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:38:23.334663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 1s/step - loss: 0.6859 - accuracy: 0.7818\n",
      "v3.h5 (fine-tuned) cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:38:27.900444: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 15.8196 - accuracy: 0.4364\n",
      "v4.h5 cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:38:32.633610: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 1s/step - loss: 17.0028 - accuracy: 0.4000\n",
      "v5.h5 (fine-tuned) cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:38:36.840514: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 0.4870 - accuracy: 0.8182\n",
      "{'v1.h5': (4.933504581451416, 0.5636363625526428), 'v2.h5': (0.6859138011932373, 0.7818182110786438), 'v3.h5': (15.819561004638672, 0.4363636374473572), 'v4.h5': (17.002777099609375, 0.4000000059604645), 'v5.h5': (0.4870135188102722, 0.8181818127632141)}\n"
     ]
    }
   ],
   "source": [
    "def create_and_load_model(model_file):\n",
    "    # Crear una instancia del modelo\n",
    "    model_instance = ImprovedTransferNetVGG19(base_model_weights=None)\n",
    "    model_instance.build((None, 224, 224, 3))  # Construir el modelo\n",
    "    \n",
    "    # Intenta cargar los pesos\n",
    "    try:\n",
    "        model_instance.load_weights(model_file)\n",
    "        print(f\"{model_file} cargado correctamente.\")\n",
    "    except Exception as e:\n",
    "        # Si hay un error, asumimos que es un modelo fine-tuned\n",
    "        model_instance.unfreeze_last_layers(num_layers=6)\n",
    "        model_instance.load_weights(model_file)\n",
    "        print(f\"{model_file} (fine-tuned) cargado correctamente.\")\n",
    "    \n",
    "    return model_instance\n",
    "\n",
    "# Compilar y evaluar los modelos\n",
    "results = {}\n",
    "for model_file in [\"v1.h5\", \"v2.h5\", \"v3.h5\", \"v4.h5\",\"v5.h5\"]:\n",
    "    model = create_and_load_model(model_file)\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Evaluar el modelo con tu conjunto de validación/test\n",
    "    loss, accuracy = model.evaluate(validation_data)\n",
    "    \n",
    "    results[model_file] = (loss, accuracy)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mlen\u001b[39m(validation_data)\n\u001b[0;32m----> 2\u001b[0m x_val, y_val \u001b[39m=\u001b[39m validation_data\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "len(validation_data)\n",
    "x_val, y_val = validation_data  # Si es una lista o tupla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' block1_conv1/kernel:0': Shape mismatch.The variable shape (3, 3, 3, 64), and the assigned value shape (512, 512, 3, 3) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m metrics \u001b[39m=\u001b[39m {}\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m---> 30\u001b[0m     recall, f1, conf_matrix \u001b[39m=\u001b[39m evaluate_model(model, model_instance, x_val, y_val)\n\u001b[1;32m     31\u001b[0m     metrics[model] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m: recall, \u001b[39m\"\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m\"\u001b[39m: f1, \u001b[39m\"\u001b[39m\u001b[39mconfusion_matrix\u001b[39m\u001b[39m\"\u001b[39m: conf_matrix}\n\u001b[1;32m     33\u001b[0m \u001b[39m# Mostrar resultados\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[45], line 17\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(filename, model_instance, x_val, y_val)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_model\u001b[39m(filename, model_instance, x_val, y_val):\n\u001b[0;32m---> 17\u001b[0m     model_instance\u001b[39m.\u001b[39;49mload_weights(filename)\n\u001b[1;32m     18\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(model_instance\u001b[39m.\u001b[39mpredict(x_val), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m     recall \u001b[39m=\u001b[39m recall_score(y_val, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# 'macro' calcula métricas para cada etiqueta y encuentra su media no ponderada\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.8/site-packages/keras/src/backend.py:4361\u001b[0m, in \u001b[0;36m_assign_value_to_variable\u001b[0;34m(variable, value)\u001b[0m\n\u001b[1;32m   4358\u001b[0m     variable\u001b[39m.\u001b[39massign(d_value)\n\u001b[1;32m   4359\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4360\u001b[0m     \u001b[39m# For the normal tf.Variable assign\u001b[39;00m\n\u001b[0;32m-> 4361\u001b[0m     variable\u001b[39m.\u001b[39;49massign(value)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' block1_conv1/kernel:0': Shape mismatch.The variable shape (3, 3, 3, 64), and the assigned value shape (512, 512, 3, 3) are incompatible."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, confusion_matrix\n",
    "def extract_data_from_generator(generator):\n",
    "    x_val_list = []\n",
    "    y_val_list = []\n",
    "\n",
    "    for i in range(len(generator)):\n",
    "        x_batch, y_batch = generator[i]\n",
    "        x_val_list.extend(x_batch)\n",
    "        y_val_list.extend(y_batch)\n",
    "\n",
    "    return np.array(x_val_list), np.array(y_val_list)\n",
    "\n",
    "x_val, y_val = extract_data_from_generator(validation_data)\n",
    "\n",
    "# Función para evaluar un modelo\n",
    "def evaluate_model(filename, model_instance, x_val, y_val):\n",
    "    model_instance.load_weights(filename)\n",
    "    y_pred = np.argmax(model_instance.predict(x_val), axis=1)\n",
    "    \n",
    "    recall = recall_score(y_val, y_pred, average='macro') # 'macro' calcula métricas para cada etiqueta y encuentra su media no ponderada\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    \n",
    "    return recall, f1, conf_matrix\n",
    "# Evaluar cada modelo\n",
    "models = [\"v1.h5\", \"v2.h5\", \"v3.h5\", \"v4.h5\", \"v5.h5\"]\n",
    "metrics = {}\n",
    "\n",
    "for model in models:\n",
    "    recall, f1, conf_matrix = evaluate_model(model, model_instance, x_val, y_val)\n",
    "    metrics[model] = {\"recall\": recall, \"f1\": f1, \"confusion_matrix\": conf_matrix}\n",
    "\n",
    "# Mostrar resultados\n",
    "for model, values in metrics.items():\n",
    "    print(f\"Model {model}:\")\n",
    "    print(f\"Recall: {values['recall']}\")\n",
    "    print(f\"F1-score: {values['f1']}\")\n",
    "    print(f\"Confusion Matrix:\\n{values['confusion_matrix']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1.h5 (fine-tuned) cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:52:33.552357: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 2s/step\n",
      "v2.h5 cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:52:37.226437: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 1s/step\n",
      "v3.h5 (fine-tuned) cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:52:40.488929: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 1s/step\n",
      "v4.h5 cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:52:43.565859: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 1s/step\n",
      "v5.h5 (fine-tuned) cargado correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 20:52:46.696913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2f5a95af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2f5a95af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 1s/step\n",
      "Model v1.h5:\n",
      "Recall: 0.48351648351648346\n",
      "F1-score: 0.37962962962962965\n",
      "Confusion Matrix:\n",
      "[[14  0  0  0]\n",
      " [14  0  0  0]\n",
      " [10  0  1  2]\n",
      " [ 2  0  0 12]]\n",
      "\n",
      "Model v2.h5:\n",
      "Recall: 0.8186813186813188\n",
      "F1-score: 0.8158195970695971\n",
      "Confusion Matrix:\n",
      "[[14  0  0  0]\n",
      " [ 4 10  0  0]\n",
      " [ 0  0 11  2]\n",
      " [ 0  0  4 10]]\n",
      "\n",
      "Model v3.h5:\n",
      "Recall: 0.4642857142857143\n",
      "F1-score: 0.39086956521739136\n",
      "Confusion Matrix:\n",
      "[[ 0  3  8  3]\n",
      " [ 0  6  8  0]\n",
      " [ 0  0 13  0]\n",
      " [ 0  0  8  6]]\n",
      "\n",
      "Model v4.h5:\n",
      "Recall: 0.42857142857142855\n",
      "F1-score: 0.3348684210526316\n",
      "Confusion Matrix:\n",
      "[[ 9  0  5  0]\n",
      " [ 1  0 13  0]\n",
      " [ 0  0 13  0]\n",
      " [ 0  0 13  1]]\n",
      "\n",
      "Model v5.h5:\n",
      "Recall: 0.8159340659340659\n",
      "F1-score: 0.8131029793021378\n",
      "Confusion Matrix:\n",
      "[[14  0  0  0]\n",
      " [ 5  9  0  0]\n",
      " [ 0  0  9  4]\n",
      " [ 0  0  1 13]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def extract_data_from_generator(generator):\n",
    "    x_val_list = []\n",
    "    y_val_list = []\n",
    "\n",
    "    for i in range(len(generator)):\n",
    "        x_batch, y_batch = generator[i]\n",
    "        x_val_list.extend(x_batch)\n",
    "        y_val_list.extend(y_batch)\n",
    "\n",
    "    return np.array(x_val_list), np.array(y_val_list)\n",
    "\n",
    "x_val, y_val = extract_data_from_generator(validation_data)\n",
    "\n",
    "# Función para evaluar un modelo\n",
    "def evaluate_model(filename):\n",
    "    model_instance = create_and_load_model(filename)\n",
    "    y_pred = np.argmax(model_instance.predict(x_val), axis=1)\n",
    "    \n",
    "    recall = recall_score(y_val, y_pred, average='macro') # 'macro' calcula métricas para cada etiqueta y encuentra su media no ponderada\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    \n",
    "    return recall, f1, conf_matrix\n",
    "\n",
    "# Evaluar cada modelo\n",
    "models = [\"v1.h5\", \"v2.h5\", \"v3.h5\", \"v4.h5\", \"v5.h5\"]\n",
    "metrics = {}\n",
    "\n",
    "for model in models:\n",
    "    recall, f1, conf_matrix = evaluate_model(model)\n",
    "    metrics[model] = {\"recall\": recall, \"f1\": f1, \"confusion_matrix\": conf_matrix}\n",
    "\n",
    "# Mostrar resultados\n",
    "for model, values in metrics.items():\n",
    "    print(f\"Model {model}:\")\n",
    "    print(f\"Recall: {values['recall']}\")\n",
    "    print(f\"F1-score: {values['f1']}\")\n",
    "    print(f\"Confusion Matrix:\\n{values['confusion_matrix']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
